_wandb:
    value:
        cli_version: 0.19.6
        m: []
        python_version: 3.9.21
        t:
            "1":
                - 1
                - 55
            "2":
                - 1
                - 55
            "3":
                - 13
                - 16
                - 23
                - 55
            "4": 3.9.21
            "5": 0.19.6
            "8":
                - 5
            "12": 0.19.6
            "13": linux-x86_64
action_size:
    value: 3
agent_pos:
    value: null
agent_types_list:
    value:
        - 0
        - 1
        - 10
agent_view_size:
    value: 7
algorithm_name:
    value: amat
asynch:
    value: true
aux_epoch:
    value: 5
block_chance:
    value: 0.25
block_doors:
    value: false
clip_param:
    value: 0.05
clone_coef:
    value: 1
com_sigma:
    value: 5
critic_lr:
    value: 0.0005
cuda:
    value: true
cuda_deterministic:
    value: true
data_chunk_length:
    value: 10
dec_actor:
    value: false
detect_traces:
    value: true
embed_hidden_size:
    value: 64
encode_state:
    value: false
entropy_coef:
    value: 0.01
env_name:
    value: GridWorld
episode_length:
    value: 200
eval_episodes:
    value: 32
eval_interval:
    value: 25
eval_maps:
    value: null
experiment_name:
    value: MAT_for_target_finding
gae_lambda:
    value: 0.95
gain:
    value: 0.01
gamma:
    value: 1
goal_history_decay:
    value: 0
grid_size:
    value: 20
hidden_size:
    value: 64
huber_delta:
    value: 10
ifi:
    value: 0.1
layer_N:
    value: 2
local_step_num:
    value: 10
log_interval:
    value: 1
lr:
    value: 0.0001
max_grad_norm:
    value: 10
max_steps:
    value: 200
max_timestep:
    value: 200
model_dir:
    value: null
n_agent_types:
    value: 2
n_block:
    value: 1
n_embd:
    value: 192
n_embd_vit:
    value: 48
n_eval_rollout_threads:
    value: 1
n_head:
    value: 1
n_render_rollout_threads:
    value: 1
n_rollout_threads:
    value: 64
n_training_threads:
    value: 4
num_agents:
    value: 3
num_env_steps:
    value: 800000000
num_mini_batch:
    value: 1
num_obstacles:
    value: 30
opti_eps:
    value: 1e-05
path_prediction_decay:
    value: 0.8
policy_value_loss_coef:
    value: 1
ppo_epoch:
    value: 10
recurrent_N:
    value: 1
recurrent_hidden_size:
    value: 192
render_episodes:
    value: 5
save_gifs:
    value: false
save_interval:
    value: 1
scenario_name:
    value: MiniGrid-SearchAndRescue-v0
seed:
    value: 2
share_actor:
    value: false
share_policy:
    value: true
stacked_frames:
    value: 1
tau:
    value: 0.995
train_maps:
    value: null
trajectory_forget_rate:
    value: 0.9145
use_ReLU:
    value: true
use_action_masking:
    value: true
use_agent_obstacle:
    value: true
use_centralized_V:
    value: true
use_clipped_value_loss:
    value: true
use_energy_penalty:
    value: true
use_eval:
    value: false
use_feature_normalization:
    value: true
use_full_comm:
    value: true
use_gae:
    value: true
use_huber_loss:
    value: true
use_intrinsic_reward:
    value: false
use_linear_lr_decay:
    value: true
use_max_grad_norm:
    value: true
use_naive_recurrent_policy:
    value: false
use_orientation:
    value: false
use_orthogonal:
    value: true
use_partial_comm:
    value: false
use_policy_active_masks:
    value: true
use_policy_vhead:
    value: false
use_popart:
    value: false
use_proper_time_limits:
    value: false
use_recurrent_decoder:
    value: false
use_recurrent_encoder:
    value: false
use_recurrent_policy:
    value: false
use_render:
    value: false
use_same_location:
    value: false
use_single_network:
    value: false
use_stacked_frames:
    value: false
use_time:
    value: false
use_time_penalty:
    value: false
use_value_active_masks:
    value: true
use_valuenorm:
    value: true
use_wandb:
    value: true
user_name:
    value: mylad
value_loss_coef:
    value: 1
wandb_name:
    value: mylad
weight_decay:
    value: 0
